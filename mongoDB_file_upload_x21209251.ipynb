{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e38852f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main function\n",
      "Function call to connect with mongoDB server\n",
      "Successfully connected to mongoDB\n",
      "Successfully connected/created database\n",
      "Successfully created table changeInSeaLevel\n",
      "Successfully created table surfaceTemperature\n",
      "Successfully created table naturalDisaster\n",
      "Function call to get csv data from Kaggle\n",
      "Pulling data from Kaggle for all-natural-disasters-19002021-eosdis\n",
      "Downloading all-natural-disasters-19002021-eosdis.zip to C:\\NCI Content\\DAP Lab\\Project\n",
      "\n",
      "File successfully downloaded for all-natural-disasters-19002021-eosdis\n",
      "Pulling data from Kaggle for climate-change-earth-surface-temperature-data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/2.31M [00:00<?, ?B/s]\n",
      " 43%|####3     | 1.00M/2.31M [00:00<00:00, 9.11MB/s]\n",
      " 86%|########6 | 2.00M/2.31M [00:00<00:00, 9.73MB/s]\n",
      "100%|##########| 2.31M/2.31M [00:00<00:00, 10.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading climate-change-earth-surface-temperature-data.zip to C:\\NCI Content\\DAP Lab\\Project\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/84.7M [00:00<?, ?B/s]\n",
      "  1%|1         | 1.00M/84.7M [00:00<00:10, 8.20MB/s]\n",
      "  4%|3         | 3.00M/84.7M [00:00<00:08, 10.4MB/s]\n",
      "  6%|5         | 5.00M/84.7M [00:00<00:07, 11.4MB/s]\n",
      "  8%|8         | 7.00M/84.7M [00:00<00:06, 12.1MB/s]\n",
      " 11%|#         | 9.00M/84.7M [00:00<00:06, 12.2MB/s]\n",
      " 13%|#2        | 11.0M/84.7M [00:00<00:06, 12.3MB/s]\n",
      " 15%|#5        | 13.0M/84.7M [00:01<00:06, 12.4MB/s]\n",
      " 18%|#7        | 15.0M/84.7M [00:01<00:05, 12.2MB/s]\n",
      " 20%|##        | 17.0M/84.7M [00:01<00:05, 12.3MB/s]\n",
      " 22%|##2       | 19.0M/84.7M [00:01<00:05, 12.1MB/s]\n",
      " 25%|##4       | 21.0M/84.7M [00:01<00:05, 12.2MB/s]\n",
      " 27%|##7       | 23.0M/84.7M [00:02<00:05, 12.2MB/s]\n",
      " 30%|##9       | 25.0M/84.7M [00:02<00:05, 12.4MB/s]\n",
      " 32%|###1      | 27.0M/84.7M [00:02<00:04, 12.2MB/s]\n",
      " 34%|###4      | 29.0M/84.7M [00:02<00:04, 12.6MB/s]\n",
      " 37%|###6      | 31.0M/84.7M [00:02<00:04, 12.5MB/s]\n",
      " 39%|###8      | 33.0M/84.7M [00:02<00:04, 12.2MB/s]\n",
      " 41%|####1     | 35.0M/84.7M [00:03<00:04, 12.3MB/s]\n",
      " 44%|####3     | 37.0M/84.7M [00:03<00:04, 12.2MB/s]\n",
      " 46%|####6     | 39.0M/84.7M [00:03<00:03, 12.3MB/s]\n",
      " 48%|####8     | 41.0M/84.7M [00:03<00:03, 12.4MB/s]\n",
      " 51%|#####     | 43.0M/84.7M [00:03<00:03, 12.3MB/s]\n",
      " 53%|#####3    | 45.0M/84.7M [00:03<00:03, 12.2MB/s]\n",
      " 55%|#####5    | 47.0M/84.7M [00:04<00:03, 12.5MB/s]\n",
      " 58%|#####7    | 49.0M/84.7M [00:04<00:03, 12.3MB/s]\n",
      " 60%|######    | 51.0M/84.7M [00:04<00:02, 12.3MB/s]\n",
      " 63%|######2   | 53.0M/84.7M [00:04<00:02, 12.1MB/s]\n",
      " 65%|######4   | 55.0M/84.7M [00:04<00:02, 12.4MB/s]\n",
      " 67%|######7   | 57.0M/84.7M [00:04<00:02, 12.3MB/s]\n",
      " 70%|######9   | 59.0M/84.7M [00:05<00:02, 12.4MB/s]\n",
      " 72%|#######1  | 61.0M/84.7M [00:05<00:02, 9.95MB/s]\n",
      " 74%|#######4  | 63.0M/84.7M [00:05<00:02, 10.6MB/s]\n",
      " 77%|#######6  | 65.0M/84.7M [00:05<00:01, 11.2MB/s]\n",
      " 79%|#######9  | 67.0M/84.7M [00:05<00:01, 11.7MB/s]\n",
      " 81%|########1 | 69.0M/84.7M [00:06<00:01, 12.0MB/s]\n",
      " 84%|########3 | 71.0M/84.7M [00:06<00:01, 12.0MB/s]\n",
      " 86%|########6 | 73.0M/84.7M [00:06<00:01, 12.0MB/s]\n",
      " 89%|########8 | 75.0M/84.7M [00:06<00:00, 12.1MB/s]\n",
      " 91%|######### | 77.0M/84.7M [00:06<00:00, 11.9MB/s]\n",
      " 93%|#########3| 79.0M/84.7M [00:06<00:00, 12.1MB/s]\n",
      " 96%|#########5| 81.0M/84.7M [00:07<00:00, 12.3MB/s]\n",
      " 98%|#########7| 83.0M/84.7M [00:07<00:00, 12.3MB/s]\n",
      "100%|##########| 84.7M/84.7M [00:07<00:00, 9.44MB/s]\n",
      "100%|##########| 84.7M/84.7M [00:07<00:00, 11.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully downloaded for climate-change-earth-surface-temperature-data\n",
      "Function call to get json data from IMF and load to mongoDB\n",
      "Data for change in sea level successfully loaded to mongoDB. Records loaded: 35604\n",
      "Function call to load csv data to mongoDB\n",
      "Loading data for surface temperature\n",
      "Data for surface temperature successfully loaded to mongoDB.\n",
      "Loading data for natural disaster\n",
      "Data for natural disaster successfully loaded to mongoDB.\n",
      "MongoDB connection closed\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "#Name: Shweta Ydaav\n",
    "#Student ID : 21209251\n",
    "#Purpose : To acquire input json/csv file from web using api and uploading it to mongodb nosql database using python\n",
    "#######################################################\n",
    "import pymongo\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from zipfile import ZipFile #importing the zipfile module\n",
    "\n",
    "#Kaggle credential to read data from kaggle API\n",
    "kaggleUsername = \"panda05\"\n",
    "kaggleKey = \"c25dc978d7e3721eccfd1f4814846223\"\n",
    "\n",
    "#Setting the enovironmemt credential variables\n",
    "os.environ['KAGGLE_USERNAME'] = kaggleUsername\n",
    "os.environ['KAGGLE_KEY'] = kaggleKey\n",
    "\n",
    "\n",
    "def mongoDBConnection():\n",
    "    try:\n",
    "        #Setting port number for localhost\n",
    "        dbPortNumber = '27017'  \n",
    "        #Create a client to connect to server DB\n",
    "        mongoClient = pymongo.MongoClient(f'mongodb://localhost:{dbPortNumber}')\n",
    "        print(\"Successfully connected to mongoDB\")\n",
    "        #Connect to database if exists, create db if it doesn't exist.\n",
    "        mongoDB = mongoClient['dapDatabase']\n",
    "        print(\"Successfully connected/created database\")\n",
    "        #Create  the tables in the database.\n",
    "        changeInSeaLevel = mongoDB['changeInSeaLevel']\n",
    "        print(\"Successfully created table changeInSeaLevel\")\n",
    "        surfaceTemperature = mongoDB['surfaceTemperature']\n",
    "        print(\"Successfully created table surfaceTemperature\")\n",
    "        naturalDisaster = mongoDB['naturalDisaster']\n",
    "        print(\"Successfully created table naturalDisaster\")\n",
    "        return mongoClient, changeInSeaLevel, surfaceTemperature, naturalDisaster\n",
    "    except Exception as e:\n",
    "        print(\"Connection to mongoDB failed with error: \"+str(e))\n",
    "        sys.exit(1)   \n",
    "\n",
    "#Kaggle API call to download the data folder\n",
    "def kaggleAPICall(dataset, folder):\n",
    "    print(\"Pulling data from Kaggle for \"+ dataset)\n",
    "    try:\n",
    "        if ('natural' in dataset):\n",
    "            !kaggle datasets download -d brsdincer/all-natural-disasters-19002021-eosdis\n",
    "        else:\n",
    "            !kaggle datasets download -d berkeleyearth/climate-change-earth-surface-temperature-data\n",
    "        #Extracting the data file from downloaded zip\n",
    "        with ZipFile(dataset+\".zip\", 'r') as zObject:\n",
    "            zObject.extractall(path = folder)\n",
    "            #Deleting the zipped folder\n",
    "        os.remove(dataset+\".zip\")\n",
    "        print(\"File successfully downloaded for \"+dataset)\n",
    "    except Exception as e:\n",
    "        print(\"Data download failed for \"+ dataset+ \" with error :\" + str(e))\n",
    "        sys.exit(1)\n",
    "\n",
    "#Function to load json data from IMF\n",
    "def imfJsonDataLoad(changeInSeaLevel):\n",
    "    #API call to load data for change in sea level\n",
    "    #The API can only pull 2000 records in one call. Using exceededTransferLimit parameter in api response to loop and pull all 35k records\n",
    "    response = requests.get('https://services9.arcgis.com/weJ1QsnbMYJlCHdG/arcgis/rest/services/Indicator_3_3_melted_new/FeatureServer/0/query?where=1%3D1&resultRecordCount=35000&outFields=*&outSR=4326&f=json')\n",
    "    listToWrite = response.json()\n",
    "    count = 0\n",
    "    offset = 0\n",
    "    try :\n",
    "        while (listToWrite['exceededTransferLimit']):\n",
    "            lisOfRecords = listToWrite['features']\n",
    "            for item in lisOfRecords:\n",
    "                attr = item['attributes']\n",
    "                attr['ObjectId'] = str(attr['ObjectId'])\n",
    "                attr['Country'] = str(attr['Country'])\n",
    "                attr['ISO2'] = str(attr['ISO2'])\n",
    "                attr['ISO3'] = str(attr['ISO3'])\n",
    "                attr['Indicator'] = str(attr['Indicator'])\n",
    "                attr['Unit'] = str(attr['Unit'])\n",
    "                attr['Source'] = str(attr['Source'])\n",
    "                attr['CTS_Code'] = str(attr['CTS_Code'])\n",
    "                attr['CTS_Name'] = str(attr['CTS_Name'])\n",
    "                attr['CTS_Full_Descriptor'] = str(attr['CTS_Full_Descriptor'])\n",
    "                attr['Measure'] = str(attr['Measure'])\n",
    "                attr['Date'] = str(attr['Date'])\n",
    "                attr['Value'] = str(attr['Value'])\n",
    "                insertProcess = changeInSeaLevel.insert_one(attr)\n",
    "                count = count+1\n",
    "            offset = offset + 2000\n",
    "            response = requests.get('https://services9.arcgis.com/weJ1QsnbMYJlCHdG/arcgis/rest/services/Indicator_3_3_melted_new/FeatureServer/0/query?where=1%3D1&resultOffset='+str(offset)+'&outFields=*&outSR=4326&f=json')\n",
    "            listToWrite = response.json()\n",
    "    except Exception as e:\n",
    "        if (\"'exceededTransferLimit'\" in str(e)):\n",
    "            lisOfRecords = listToWrite['features']\n",
    "            for item in lisOfRecords:\n",
    "                attr = item['attributes']\n",
    "                attr['ObjectId'] = str(attr['ObjectId'])\n",
    "                attr['Country'] = str(attr['Country'])\n",
    "                attr['ISO2'] = str(attr['ISO2'])\n",
    "                attr['ISO3'] = str(attr['ISO3'])\n",
    "                attr['Indicator'] = str(attr['Indicator'])\n",
    "                attr['Unit'] = str(attr['Unit'])\n",
    "                attr['Source'] = str(attr['Source'])\n",
    "                attr['CTS_Code'] = str(attr['CTS_Code'])\n",
    "                attr['CTS_Name'] = str(attr['CTS_Name'])\n",
    "                attr['CTS_Full_Descriptor'] = str(attr['CTS_Full_Descriptor'])\n",
    "                attr['Measure'] = str(attr['Measure'])\n",
    "                attr['Date'] = str(attr['Date'])\n",
    "                attr['Value'] = str(attr['Value'])\n",
    "                insertProcess = changeInSeaLevel.insert_one(attr)\n",
    "                count = count+1\n",
    "        else:\n",
    "            print(\"Data load failed with error: \"+str(e))\n",
    "            sys.exit(1)\n",
    "    #total number of records loaded in data\n",
    "    print(\"Data for change in sea level successfully loaded to mongoDB. Records loaded: \"+ str(count))    \n",
    "\n",
    "#Function to load Kaggle csv data from local\n",
    "def kaggleCsvDataLoad(surfaceTemperature, naturalDisaster):    \n",
    "    #loading data for surface temperature\n",
    "    print(\"Loading data for surface temperature\")\n",
    "    try:\n",
    "        data = pd.read_csv('surface-temperature/GlobalLandTemperaturesByMajorCity.csv')\n",
    "        docs = json.loads(data.T.to_json()).values()\n",
    "        surfaceTemperature.insert_many(docs)\n",
    "        print(\"Data for surface temperature successfully loaded to mongoDB.\")\n",
    "    except Exception as e:\n",
    "        print('Data load to mongodb failed with error '+ str(e))\n",
    "        sys.exit(1)\n",
    "\n",
    "    #loading data for natural disaster\n",
    "    print(\"Loading data for natural disaster\")\n",
    "    try:\n",
    "        data = pd.read_csv('natural-disaster/DISASTERS/1970-2021_DISASTERS.xlsx - emdat data.csv')\n",
    "        docs = json.loads(data.T.to_json()).values()\n",
    "        naturalDisaster.insert_many(docs)\n",
    "        print(\"Data for natural disaster successfully loaded to mongoDB.\")\n",
    "    except Exception as e:\n",
    "        print('Data load to mongodb failed with error '+ str(e)) \n",
    "        sys.exit(1)    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    try:\n",
    "        print(\"Main function\")\n",
    "        print(\"Function call to connect with mongoDB server\")\n",
    "        mongoClient, table1, table2, table3 = mongoDBConnection()\n",
    "        print(\"Function call to get csv data from Kaggle\")\n",
    "        kaggleAPICall('all-natural-disasters-19002021-eosdis', 'natural-disaster')\n",
    "        kaggleAPICall('climate-change-earth-surface-temperature-data', 'surface-temperature')\n",
    "        print(\"Function call to get json data from IMF and load to mongoDB\")\n",
    "        imfJsonDataLoad(table1)\n",
    "        print(\"Function call to load csv data to mongoDB\")\n",
    "        kaggleCsvDataLoad(table2, table3)\n",
    "        mongoClient.close()\n",
    "        print(\"MongoDB connection closed\")\n",
    "    except Exception as e:\n",
    "        print('Exception raised '+ str(e))\n",
    "        print(\"Error in main function\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fa0c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
